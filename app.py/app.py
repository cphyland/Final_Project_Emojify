{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, redirect\n",
    "import flask_functions\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from flask import request\n",
    "from flask import jsonify\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pdb\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_api_url = \"http://api.fish.wa.gov.au/webapi/v1/RawData\"\n",
    "shark_table_name = \"sharks1\"\n",
    "shark_csv_path = \"../data/sharks/sharks_cleaned.csv\"\n",
    "\n",
    "# Flask Setup\n",
    "app = Flask(__name__)\n",
    "\n",
    "def get_model():\n",
    "\tglobal model\n",
    "\tmodel = load_model('emoji_model.h5')\n",
    "\tprint('Model Loaded!!')\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# Flask Routes\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "  return render_template(\"View_.html\")\n",
    "\n",
    "@app.route('/predict',methods = ['POST'])\n",
    "def predict():\n",
    "\tglobal graph\n",
    "\tglobal tokenizer\n",
    "\twith graph.as_default():\n",
    "\t\tmaxlen = 50\n",
    "\t\ttext = request.form['name']\n",
    "\t\ttest_sent = tokenizer.texts_to_sequences([text])\n",
    "\t\ttest_sent = pad_sequences(test_sent, maxlen = maxlen)\n",
    "\t\tpred = model.predict(test_sent)\n",
    "\t\tresponse = {\n",
    "\t\t'prediction': int(np.argmax(pred))\n",
    "\t\t}\n",
    "\treturn jsonify(response)\n",
    "\n",
    "@app.route('/update',methods = ['POST'])\n",
    "def update():\n",
    "\tglobal graph\n",
    "\tglobal tokenizer\n",
    "\twith graph.as_default():\n",
    "\t\tmaxlen = 50\n",
    "\t\ttext = request.form['sentence']\n",
    "\t\ttest_sent = tokenizer.texts_to_sequences([text])\n",
    "\t\ttest_sent = pad_sequences(test_sent, maxlen = maxlen)\n",
    "\t\ttest_sent = np.vstack([test_sent] * 5)\n",
    "\t\tactual_output = request.form['dropdown_value']\n",
    "\t\toutput_hash = {\n",
    "\t\t\t'Happy': np.array([1.,0.,0.,0.,0.,0.,0.]),\n",
    "\t\t\t'Fear': np.array([0.,1.,0.,0.,0.,0.,0.]),\n",
    "\t\t\t'Angry': np.array([0.,0.,1.,0.,0.,0.,0.]),\n",
    "\t\t\t'Sad': np.array([0.,0.,0.,1.,0.,0.,0.]),\n",
    "\t\t\t'Disgust': np.array([0.,0.,0.,0.,1.,0.,0.]),\n",
    "\t\t\t'Neutral': np.array([0.,0.,0.,0.,0.,1.,0.]),\n",
    "\t\t\t'Surprise': np.array([0.,0.,0.,0.,0.,0.,1.]),\n",
    "\t\t\t\t\t}\n",
    "\t\tactual_output = output_hash[actual_output].reshape((1,7))\n",
    "\t\tactual_output = np.vstack([actual_output] * 5)\n",
    "\t\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t\tmodel.fit(test_sent, actual_output, epochs = 10, batch_size = 32, shuffle=True)\n",
    "\t\tmodel.save('emoji_model.h5')\n",
    "\t\tget_model()\n",
    "\t\tresponse = {\n",
    "\t\t'update_text': 'Updated the values!! Should work in next few attempts..'\n",
    "\t\t}\n",
    "\treturn redirect(\"/\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tget_model()\n",
    "\tapp.run(host=\"0.0.0.0\", port=5000,debug=False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
